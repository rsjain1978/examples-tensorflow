{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.Estimator based iris classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorboard as tb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris_data = load_iris()\n",
    "x = iris_data.data\n",
    "y = iris_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_columns = []\n",
    "my_feature_columns.append(tf.feature_column.numeric_column(key='SepalLength'))\n",
    "my_feature_columns.append(tf.feature_column.numeric_column(key='SepalWidth'))\n",
    "my_feature_columns.append(tf.feature_column.numeric_column(key='PetalLength'))\n",
    "my_feature_columns.append(tf.feature_column.numeric_column(key='PetalWidth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 00:08:34.278457  7008 estimator.py:1811] Using temporary folder as model directory: C:\\Users\\ADITYA~1\\AppData\\Local\\Temp\\tmpcq29l6ya\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers and 10 nodes in each hidden layer.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[50, 50],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\n",
    "                'SepalLength': X_train[:,0:1],\n",
    "                'SepalWidth':  X_train[:,1:2],\n",
    "                'PetalLength': X_train[:,2:3],\n",
    "                'PetalWidth':  X_train[:,3:4]\n",
    "               },\n",
    "    y = y_train,\n",
    "    batch_size = 32,\n",
    "    num_epochs = 5,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 00:08:34.926774  7008 deprecation.py:323] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0909 00:08:34.939768  7008 deprecation.py:323] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0909 00:08:34.942759  7008 deprecation.py:323] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0909 00:08:34.954780  7008 deprecation.py:506] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 00:08:35.777774  7008 deprecation.py:323] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0909 00:08:35.875773  7008 deprecation.py:506] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 00:08:36.779119  7008 deprecation.py:323] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0909 00:08:36.950136  7008 deprecation.py:323] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x21639ee2630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\n",
    "                'SepalLength': X_test[:,0:1],\n",
    "                'SepalWidth':  X_test[:,1:2],\n",
    "                'PetalLength': X_test[:,2:3],\n",
    "                'PetalWidth':  X_test[:,3:4]\n",
    "               },\n",
    "    y = y_test,\n",
    "    batch_size = 32,\n",
    "    num_epochs = 1,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 00:08:39.692719  7008 deprecation.py:323] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model.\n",
    "eval_result = classifier.evaluate(input_fn=evaluate_input_fn)\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\n",
    "                'SepalLength': X_test[0:10,0:1],\n",
    "                'SepalWidth':  X_test[0:10,1:2],\n",
    "                'PetalLength': X_test[0:10,2:3],\n",
    "                'PetalWidth':  X_test[0:10,3:4]\n",
    "               },\n",
    "    y = y_test[0:10],\n",
    "    num_epochs = 1,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected class are  [1 1 1 0 0 1 0 1 2 0]\n",
      "Predicted class is 1\n",
      "Predicted class is 1\n",
      "Predicted class is 1\n",
      "Predicted class is 0\n",
      "Predicted class is 0\n",
      "Predicted class is 1\n",
      "Predicted class is 0\n",
      "Predicted class is 1\n",
      "Predicted class is 2\n",
      "Predicted class is 0\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(input_fn=test_input_fn)\n",
    "print ('Expected class are ',y_test[0:10])\n",
    "for p in predictions:\n",
    "    print ('Predicted class is %d'%(p['class_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
